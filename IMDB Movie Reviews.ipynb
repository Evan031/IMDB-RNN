{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Capstone.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFhZOkFZGdGj",
        "colab_type": "text"
      },
      "source": [
        "# IMDB RNN - Sentiment Analysis\n",
        "This notebook contains my method of using a recurrent neural network. We will be using the IMDB dataset provided by Keras. Since it has already been pre-processed there is no need to sanitise the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CN675dT0Ygz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "a207b176-94a0-4497-8a9f-8c58bada37aa"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRBAl9Wy0Y2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = keras.datasets.imdb\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SEYCxpEZwvZ",
        "colab_type": "text"
      },
      "source": [
        "Below we set the maximum amount of words and the variable \"maxlen\" for the padding we will use later. Max words will limit the amount of words that can be captured by the dataset. Without setting a limit the dataset might become too big.\n",
        " \n",
        "The \"maxlen\" that will be used in padding is for creating a template base size for every sentence that is passed through the X variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7bdMFXx0ZBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_words = 10240\n",
        "maxlen = 500\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_words)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-_8zGm2a0Jo",
        "colab_type": "text"
      },
      "source": [
        "Below we see the 6th value in X_train, it is read through as numbers. The reason being is that's what computers understand. Each word has been ranked according to importance and impact on the Y. The 1 which is the label means that the review is positive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMEMd_FM0ZDS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "0986e00d-5fcb-4c87-b635-5efb6b867658"
      },
      "source": [
        "print('----Review----')\n",
        "print(X_train[6])\n",
        "print('----Label----')\n",
        "print(y_train[6])\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----Review----\n",
            "[1, 6740, 365, 1234, 5, 1156, 354, 11, 14, 5327, 6638, 7, 1016, 2, 5940, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 2, 9363, 1117, 1831, 7485, 5, 4831, 26, 6, 2, 4183, 17, 369, 37, 215, 1345, 143, 2, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 2, 8564, 63, 271, 6, 196, 96, 949, 4121, 4, 2, 7, 4, 2212, 2436, 819, 63, 47, 77, 7175, 180, 6, 227, 11, 94, 2494, 2, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 5390, 99, 76, 23, 2, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]\n",
            "----Label----\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLsYUAKIbTZv",
        "colab_type": "text"
      },
      "source": [
        "As mentioned above, the values have been converted to words and you see the wording used to review this movie are very powerful. The code below also dismisses words that have a value less than 3. It's used to root out words like \"the\" and \"it\" etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ifwvVwx0ZFv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "af9eaa19-bb72-452d-c7d7-50c0710714f8"
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "review = [reverse_word_index.get(i-3, \"?\") for i in X_train[6]]\n",
        "print(review)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['?', 'lavish', 'production', 'values', 'and', 'solid', 'performances', 'in', 'this', 'straightforward', 'adaption', 'of', 'jane', '?', 'satirical', 'classic', 'about', 'the', 'marriage', 'game', 'within', 'and', 'between', 'the', 'classes', 'in', '?', '18th', 'century', 'england', 'northam', 'and', 'paltrow', 'are', 'a', '?', 'mixture', 'as', 'friends', 'who', 'must', 'pass', 'through', '?', 'and', 'lies', 'to', 'discover', 'that', 'they', 'love', 'each', 'other', 'good', 'humor', 'is', 'a', '?', 'virtue', 'which', 'goes', 'a', 'long', 'way', 'towards', 'explaining', 'the', '?', 'of', 'the', 'aged', 'source', 'material', 'which', 'has', 'been', 'toned', 'down', 'a', 'bit', 'in', 'its', 'harsh', '?', 'i', 'liked', 'the', 'look', 'of', 'the', 'film', 'and', 'how', 'shots', 'were', 'set', 'up', 'and', 'i', 'thought', 'it', \"didn't\", 'rely', 'too', 'much', 'on', '?', 'of', 'head', 'shots', 'like', 'most', 'other', 'films', 'of', 'the', '80s', 'and', '90s', 'do', 'very', 'good', 'results']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn-UUKlfb58T",
        "colab_type": "text"
      },
      "source": [
        "Below the padding is applied. Some sentences will be much shorter than others so padding adds zeros to the sentences that are smaller. This is so the model receives uniform inputs. This process is done for both train and test data so an equal comparison can be performed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHsJ6SsD0ZK7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "950ca1c1-13b2-42cd-a84d-168bd69dd145"
      },
      "source": [
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "print(X_train)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0 ...   19  178   32]\n",
            " [   0    0    0 ...   16  145   95]\n",
            " [   0    0    0 ...    7  129  113]\n",
            " ...\n",
            " [   0    0    0 ...    4 3586    2]\n",
            " [   0    0    0 ...   12    9   23]\n",
            " [   0    0    0 ...  204  131    9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RbCZw_V0ZNX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "360c96c1-8a0a-45cb-dffa-5549c3c26edb"
      },
      "source": [
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen)\n",
        "print(X_test)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0 ...   14    6  717]\n",
            " [   0    0    0 ...  125    4 3077]\n",
            " [  33    6   58 ...    9   57  975]\n",
            " ...\n",
            " [   0    0    0 ...   21  846 5518]\n",
            " [   0    0    0 ... 2302    7  470]\n",
            " [   0    0    0 ...   34 2005 2643]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNmcybqecnkI",
        "colab_type": "text"
      },
      "source": [
        "Below you see an output of \"y_train\", as mentioned earlier 1 represents a positive review, and 0 represents a negative one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kNcDxQd0ZQH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e24a3b05-8300-46d7-d6c2-9c1ebfcb2476"
      },
      "source": [
        "print(y_train[:10])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 1 0 0 1 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcEaberCeBd6",
        "colab_type": "text"
      },
      "source": [
        "## Modelling\n",
        "\n",
        "We going to try 2 different models and approaches. The first will have fewer units and use the \"rmsprop\" activation method. The second will have more units and use the \"Adamax\" activation method. Both will use the same amount of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkORMWTx0ZSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_vector_length = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_vector_length, input_length=maxlen))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rLFNKOV0ZUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ4Vaz0j0ZaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "b57e4785-c0f9-4629-ab95-e8602178d5e2"
      },
      "source": [
        "model.fit(X_train, y_train,\n",
        "          batch_size=256,\n",
        "          epochs=10,\n",
        "          validation_data=(X_test, y_test))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "98/98 [==============================] - 16s 168ms/step - loss: 0.6294 - acc: 0.6920 - val_loss: 0.5485 - val_acc: 0.7299\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 16s 166ms/step - loss: 0.4451 - acc: 0.8131 - val_loss: 0.3760 - val_acc: 0.8398\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 16s 166ms/step - loss: 0.3763 - acc: 0.8520 - val_loss: 0.4288 - val_acc: 0.8365\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 16s 166ms/step - loss: 0.3066 - acc: 0.8751 - val_loss: 0.3773 - val_acc: 0.8353\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 17s 169ms/step - loss: 0.2640 - acc: 0.8977 - val_loss: 0.4164 - val_acc: 0.8154\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 16s 168ms/step - loss: 0.2527 - acc: 0.9036 - val_loss: 0.3898 - val_acc: 0.8302\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 16s 168ms/step - loss: 0.2121 - acc: 0.9210 - val_loss: 0.4180 - val_acc: 0.8121\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 17s 170ms/step - loss: 0.1899 - acc: 0.9302 - val_loss: 0.3656 - val_acc: 0.8575\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 17s 170ms/step - loss: 0.1754 - acc: 0.9364 - val_loss: 0.3641 - val_acc: 0.8648\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 17s 170ms/step - loss: 0.1590 - acc: 0.9436 - val_loss: 0.3724 - val_acc: 0.8687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3d6bc546a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUMIHles-Goo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e945cfe7-7cdc-45b7-a564-2df07de8b6a8"
      },
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Accuracy: 86.87%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wifWunL0Zcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_vector_length = 64\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(max_words, embedding_vector_length, input_length=maxlen))\n",
        "model2.add(LSTM(512))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCO2kbV94D5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.compile(optimizer='Adamax',\n",
        "               loss='binary_crossentropy',\n",
        "               metrics=['acc'])\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zovNfVi4Iv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "3b587be0-d6ed-4141-e62c-b6b32159ef6e"
      },
      "source": [
        "model2.fit(X_train,\n",
        "           y_train,\n",
        "           batch_size=512,\n",
        "           epochs=10,\n",
        "           validation_data=(X_test, y_test))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "49/49 [==============================] - 40s 812ms/step - loss: 0.6905 - acc: 0.5619 - val_loss: 0.6841 - val_acc: 0.6018\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 40s 824ms/step - loss: 0.6709 - acc: 0.6770 - val_loss: 0.6338 - val_acc: 0.7554\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 41s 834ms/step - loss: 0.4944 - acc: 0.7958 - val_loss: 0.4301 - val_acc: 0.8104\n",
            "Epoch 4/10\n",
            "49/49 [==============================] - 41s 846ms/step - loss: 0.3611 - acc: 0.8486 - val_loss: 0.3510 - val_acc: 0.8494\n",
            "Epoch 5/10\n",
            "49/49 [==============================] - 42s 855ms/step - loss: 0.2969 - acc: 0.8834 - val_loss: 0.3163 - val_acc: 0.8670\n",
            "Epoch 6/10\n",
            "49/49 [==============================] - 42s 862ms/step - loss: 0.2766 - acc: 0.8968 - val_loss: 0.3119 - val_acc: 0.8705\n",
            "Epoch 7/10\n",
            "49/49 [==============================] - 42s 865ms/step - loss: 0.2393 - acc: 0.9110 - val_loss: 0.3003 - val_acc: 0.8756\n",
            "Epoch 8/10\n",
            "49/49 [==============================] - 43s 870ms/step - loss: 0.2185 - acc: 0.9193 - val_loss: 0.3018 - val_acc: 0.8732\n",
            "Epoch 9/10\n",
            "49/49 [==============================] - 43s 874ms/step - loss: 0.2001 - acc: 0.9282 - val_loss: 0.3518 - val_acc: 0.8706\n",
            "Epoch 10/10\n",
            "49/49 [==============================] - 43s 873ms/step - loss: 0.1875 - acc: 0.9330 - val_loss: 0.3243 - val_acc: 0.8735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3d6480e6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdLOMti3gkOz",
        "colab_type": "text"
      },
      "source": [
        "It's clear even though by a small margin the second model is the winner. We will save and test it in the following steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCPPbPaW4PS0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9ddcb0e8-8c40-4904-a980-58d281d722d5"
      },
      "source": [
        "scores = model2.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Accuracy: 87.40%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bXQEt9zCCrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.save('sentiment_analysis.h5')\n",
        "saved_model = keras.models.load_model('sentiment_analysis.h5')\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60ivi0VpgvGF",
        "colab_type": "text"
      },
      "source": [
        "Let's calculate the first 5 predicted scores and values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWYXDHa1INlL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "1759c840-4a73-488c-d510-bbbdf1693d68"
      },
      "source": [
        "predictions = saved_model.predict(X_test)\n",
        "\n",
        "[print(predictions[i], y_test[i]) for i in range(0, 5)]\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0390748] 0\n",
            "[0.9862282] 1\n",
            "[0.9715433] 1\n",
            "[0.4201262] 0\n",
            "[0.99675435] 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKKQbjahheT6",
        "colab_type": "text"
      },
      "source": [
        "Below we see the model predicted them all correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCLkH3xaJIzm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7499df8f-4f32-42cc-b02a-d6dcab34638a"
      },
      "source": [
        "print(y_test[:5])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InphtnIoh5O9",
        "colab_type": "text"
      },
      "source": [
        "# Final evaluation of the model\n",
        "Above all answers are correct, but that does not reflect the total dataset but a small subset just to show the model does work for the most part. All in all the model could be improved perhaps with more epochs or layers. The compute power might be expensive but bigger companies possess just that, and models like the one above are used in such cases, with much less error and higher accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQqyGwy-EpGi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eac37c50-cfa5-4bf8-ce17-d5be72ab3adc"
      },
      "source": [
        "\n",
        "scores = saved_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 87.35%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}